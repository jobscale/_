apiVersion: apps/v1
kind: Deployment
metadata:
  name: llama-lo
  labels:
    app: llama-lo
    component: deployment
spec:
  selector:
    matchLabels:
      app: llama-lo
  template:
    metadata:
      labels:
        app: llama-lo
        component: workload
    spec:
      containers:
      - image: ghcr.io/jobscale/reverse-proxy
        name: llama-lo
        env:
        - name: BACKEND
          value: http://llama.x.jsx.jp:2880
---
apiVersion: v1
kind: Service
metadata:
  name: llama-lo
  labels:
    app: llama-lo
    component: service
spec:
  selector:
    app: llama-lo
  type: ClusterIP
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 3000
---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: llama-lo
  labels:
    app: llama-lo
    component: route
spec:
  parentRefs:
  - name: web-gateway
    namespace: gateway-system
  hostnames:
  - "llama.jsx.jp"
  - "llama.x.jsx.jp"
  rules:
  - backendRefs:
    - name: llama-lo
      port: 80
---
apiVersion: gateway.nginx.org/v1alpha1
kind: ProxySettingsPolicy
metadata:
  name: llama-lo
  labels:
    app: llama-lo
    component: proxy-settings
spec:
  targetRefs:
  - group: gateway.networking.k8s.io
    kind: HTTPRoute
    name: llama-lo
  timeout:
    read: 3600s
    send: 3600s
